{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to representation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of representation learning is to transform data at our disposal and find a new representation of it in a new embedded space.\n",
    "This new representation may be useful for several reasons, see the excellent article by Bengio et al. for more detailed explanations: https://arxiv.org/pdf/1206.5538.pdf.\n",
    "Representations can then be used for a variety of machine learning tasks both supervised (such as prediction or classification) or unsupervised (such as clustering).\n",
    "\n",
    "In this notebook, we are going to introduce basic ideas and methods behind representation learning, applied to the MNIST dataset.\n",
    "It is a dataset that is made of images of handwritten digits and where each image is associated to the actual digit it represents.\n",
    "Note that representation learning is by no means restricted to image datasets.\n",
    "The latter are nonetheless particularly suited to illustrating techniques of representation learning as we can visualize the original data and their reconstruction (to be detailed below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading data from the MNIST dataset, it is one of the standard datasets used in `keras`, a handy Python framework for deep learning.\n",
    "Each sample is an image, i.e. a matrix of size $n \\times n = 28 \\times 28 = 784$.\n",
    "The set of all such matrices is denoted $X^{mat} \\in \\mathbb{R}^{n_{samples} \\times n \\times n}$, where $n_{samples}$ denotes the number of images available in the dataset.\n",
    "Each image is associated to a label denoting the digit to which the image corresponds.\n",
    "The set of all such labels is denoted $l \\in \\mathbb{R}^{n_{samples}}$.\n",
    "\n",
    "As is standard in machine learning, the whole dataset must be split between a training dataset, used to train algorithms, and a test dataset, on which we evaluate the performance of our algorithms.\n",
    "This is done automatically by the `keras` function `mnist.load_data()`.\n",
    "\n",
    "We therefore load the MNIST dataset and split it as $(X^{mat}_{train}, l_{train})$ and $(X^{mat}_{test}, l_{test})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.0.0:\n",
      "  Successfully uninstalled tensorflow-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip uninstall tensorflow --yes\n",
    "!pip install tensorflow --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.3.1 in c:\\users\\lea\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (1.17.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (5.1.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (2.9.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in c:\\users\\lea\\anaconda3\\lib\\site-packages (from keras==2.3.1) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-1.6.0-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-20f8fa973fcf>\", line 1, in <module>\n",
      "    import keras\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-20f8fa973fcf>\", line 1, in <module>\n",
      "    import keras\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-20f8fa973fcf>\", line 1, in <module>\n",
      "    import keras\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3342, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2042, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: must be str, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\n",
      "    from . _api.v2 import audio\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\n",
      "    from tensorflow.python.ops.gen_audio_ops import decode_wav\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-20f8fa973fcf>\", line 1, in <module>\n",
      "    import keras\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\n",
      "    from . import utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\n",
      "    from . import conv_utils\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\n",
      "    from .. import backend as K\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\n",
      "    from .load_backend import epsilon\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\n",
      "    from .tensorflow_backend import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3342, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2042, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: must be str, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\n",
      "    from tensorflow.python.pywrap_tensorflow_internal import *\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\n",
      "    _pywrap_tensorflow_internal = swig_import_helper()\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n",
      "    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 243, in load_module\n",
      "    return load_dynamic(name, filename, file)\n",
      "  File \"C:\\Users\\Lea\\Anaconda3\\lib\\imp.py\", line 343, in load_dynamic\n",
      "    return _load(spec)\n",
      "ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.\n",
      "\n",
      "\n",
      "Failed to load the native TensorFlow runtime.\n",
      "\n",
      "See https://www.tensorflow.org/install/errors\n",
      "\n",
      "for some common reasons and solutions.  Include the entire stack trace\n",
      "above this error message when asking for help.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0m_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(name, file, filename, details)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[1;34m(name, path, file)\u001b[0m\n\u001b[0;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2039\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2040\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImportError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[0;32m   3340\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3341\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3342\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3343\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3344\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2041\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2042\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2044\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1385\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1286\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1288\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m             )\n\u001b[0;32m   1290\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "(X_mat_train, l_train), (X_mat_test, l_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking shapes of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first investigate:\n",
    "- how the train and test sets have been split,\n",
    "- what the dimensions of the data we loaded are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = X_mat_train.shape[0]\n",
    "n_samples_test = X_mat_test.shape[0]\n",
    "n_samples = n_samples_train + n_samples_test\n",
    "n = X_mat_train.shape[1]\n",
    "print('n_samples_train / n_samples = {} / {} = {:.2f}'.format(n_samples_train, \n",
    "                                                              n_samples, \n",
    "                                                              n_samples_train/n_samples))\n",
    "print('n_samples_train / n_samples = {} / {} = {:.2f}'.format(n_samples_test, \n",
    "                                                              n_samples, \n",
    "                                                              n_samples_test/n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.7.1\n",
      "alabaster==0.7.12\n",
      "anaconda-client==1.7.2\n",
      "anaconda-navigator==1.10.0\n",
      "anaconda-project==0.8.3\n",
      "asn1crypto==0.24.0\n",
      "astor==0.8.0\n",
      "astroid==2.2.5\n",
      "astropy==3.2.1\n",
      "atomicwrites==1.3.0\n",
      "attrs==19.1.0\n",
      "Babel==2.7.0\n",
      "backcall==0.1.0\n",
      "backports.os==0.1.1\n",
      "backports.shutil-get-terminal-size==1.0.0\n",
      "beautifulsoup4==4.7.1\n",
      "bitarray==0.9.3\n",
      "bkcharts==0.2\n",
      "blaze==0.11.3\n",
      "bleach==3.1.0\n",
      "bokeh==1.3.0\n",
      "boto==2.49.0\n",
      "Bottleneck==1.2.1\n",
      "branca==0.4.1\n",
      "Brotli==1.0.9\n",
      "cachetools==4.2.2\n",
      "certifi==2020.12.5\n",
      "cffi==1.12.3\n",
      "chardet==3.0.4\n",
      "Click==7.0\n",
      "cloudpickle==1.2.1\n",
      "clyent==1.2.2\n",
      "colorama==0.4.1\n",
      "comtypes==1.1.7\n",
      "conda==4.10.1\n",
      "conda-build==3.10.5\n",
      "conda-package-handling==1.3.11\n",
      "conda-verify==2.0.0\n",
      "contextlib2==0.5.5\n",
      "coverage==5.3\n",
      "cryptography==2.7\n",
      "cycler==0.10.0\n",
      "Cython==0.29.12\n",
      "cytoolz==0.10.0\n",
      "dash==1.17.0\n",
      "dash-core-components==1.13.0\n",
      "dash-html-components==1.1.1\n",
      "dash-renderer==1.8.3\n",
      "dash-table==4.11.0\n",
      "dask==2.1.0\n",
      "datashape==0.5.4\n",
      "decorator==4.4.0\n",
      "defusedxml==0.6.0\n",
      "distributed==2.1.0\n",
      "docutils==0.14\n",
      "entrypoints==0.3\n",
      "et-xmlfile==1.0.1\n",
      "fastcache==1.1.0\n",
      "filelock==3.0.12\n",
      "Flask==1.1.1\n",
      "Flask-Compress==1.8.0\n",
      "Flask-Cors==3.0.4\n",
      "folium==0.11.0\n",
      "future==0.18.2\n",
      "gast==0.2.2\n",
      "gevent==1.4.0\n",
      "glob2==0.7\n",
      "google-auth==1.30.1\n",
      "google-auth-oauthlib==0.4.4\n",
      "google-pasta==0.1.7\n",
      "greenlet==0.4.15\n",
      "grpcio==1.22.0\n",
      "h5py==2.9.0\n",
      "heapdict==1.0.0\n",
      "html5lib==1.0.1\n",
      "idna==2.8\n",
      "imageio==2.5.0\n",
      "imagesize==1.1.0\n",
      "importlib-metadata==0.17\n",
      "ipykernel==5.1.1\n",
      "ipython==7.6.1\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.0\n",
      "isort==4.3.21\n",
      "itsdangerous==1.1.0\n",
      "jdcal==1.4.1\n",
      "jedi==0.13.3\n",
      "Jinja2==2.10.1\n",
      "joblib==0.13.2\n",
      "json5==0.8.4\n",
      "jsonschema==3.0.1\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.3.1\n",
      "jupyter-console==6.0.0\n",
      "jupyter-core==4.5.0\n",
      "jupyterlab==1.0.2\n",
      "jupyterlab-launcher==0.10.5\n",
      "jupyterlab-server==1.0.0\n",
      "Keras==2.3.1\n",
      "Keras-Applications==1.0.8\n",
      "Keras-Preprocessing==1.1.0\n",
      "keyring==18.0.0\n",
      "kiwisolver==1.1.0\n",
      "lazy-object-proxy==1.4.1\n",
      "libarchive-c==2.8\n",
      "llvmlite==0.29.0\n",
      "locket==0.2.0\n",
      "lxml==4.3.4\n",
      "Markdown==3.1.1\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.1.0\n",
      "mccabe==0.6.1\n",
      "menuinst==1.4.16\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.12\n",
      "mkl-random==1.0.2\n",
      "mkl-service==2.0.2\n",
      "mock==3.0.5\n",
      "more-itertools==7.0.0\n",
      "mpmath==1.1.0\n",
      "msgpack==0.6.1\n",
      "multipledispatch==0.6.0\n",
      "navigator-updater==0.2.1\n",
      "nbconvert==5.5.0\n",
      "nbformat==4.4.0\n",
      "networkx==2.3\n",
      "nltk==3.4.4\n",
      "nose==1.3.7\n",
      "notebook==6.0.0\n",
      "numba==0.45.0\n",
      "numexpr==2.6.9\n",
      "numpy==1.17.0\n",
      "numpydoc==0.9.1\n",
      "oauthlib==3.1.0\n",
      "odo==0.5.1\n",
      "olefile==0.46\n",
      "openpyxl==2.6.2\n",
      "opt-einsum==3.3.0\n",
      "packaging==19.0\n",
      "pandas==0.24.2\n",
      "pandocfilters==1.4.2\n",
      "parso==0.5.0\n",
      "partd==1.0.0\n",
      "path.py==12.0.1\n",
      "pathlib2==2.3.4\n",
      "patsy==0.5.1\n",
      "pep8==1.7.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==6.1.0\n",
      "pkginfo==1.5.0.1\n",
      "plotly==4.12.0\n",
      "pluggy==0.12.0\n",
      "ply==3.11\n",
      "prometheus-client==0.7.1\n",
      "prompt-toolkit==2.0.9\n",
      "protobuf==3.9.0\n",
      "psutil==5.6.3\n",
      "py==1.8.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycodestyle==2.5.0\n",
      "pycosat==0.6.3\n",
      "pycparser==2.19\n",
      "pycrypto==2.6.1\n",
      "pycurl==7.43.0.3\n",
      "pyflakes==2.1.1\n",
      "Pygments==2.4.2\n",
      "pylint==2.3.1\n",
      "pyodbc==4.0.26\n",
      "pyOpenSSL==19.0.0\n",
      "pyparsing==2.4.0\n",
      "pyqtgraph==0.10.0\n",
      "pyreadline==2.1\n",
      "pyrsistent==0.14.11\n",
      "pyserial==3.4\n",
      "PySocks==1.7.0\n",
      "pytest==5.0.1\n",
      "pytest-arraydiff==0.3\n",
      "pytest-astropy==0.5.0\n",
      "pytest-cov==2.10.1\n",
      "pytest-doctestplus==0.3.0\n",
      "pytest-openfiles==0.3.2\n",
      "pytest-remotedata==0.3.1\n",
      "python-dateutil==2.8.0\n",
      "pytz==2019.1\n",
      "PyWavelets==1.0.3\n",
      "pywin32==223\n",
      "pywinpty==0.5.5\n",
      "PyYAML==5.1.1\n",
      "pyzmq==18.0.0\n",
      "QtAwesome==0.5.7\n",
      "qtconsole==4.5.2\n",
      "QtPy==1.8.0\n",
      "requests==2.22.0\n",
      "requests-oauthlib==1.3.0\n",
      "retrying==1.3.3\n",
      "rope==0.14.0\n",
      "rsa==4.7.2\n",
      "ruamel-yaml==0.15.46\n",
      "scikit-image==0.15.0\n",
      "scikit-learn==0.21.2\n",
      "scipy==1.2.1\n",
      "seaborn==0.9.0\n",
      "Send2Trash==1.5.0\n",
      "simplegeneric==0.8.1\n",
      "singledispatch==3.4.0.3\n",
      "six==1.12.0\n",
      "snowballstemmer==1.9.0\n",
      "sortedcollections==1.1.2\n",
      "sortedcontainers==2.1.0\n",
      "soupsieve==1.8\n",
      "Sphinx==2.1.2\n",
      "sphinxcontrib-applehelp==1.0.1\n",
      "sphinxcontrib-devhelp==1.0.1\n",
      "sphinxcontrib-htmlhelp==1.0.2\n",
      "sphinxcontrib-jsmath==1.0.1\n",
      "sphinxcontrib-qthelp==1.0.2\n",
      "sphinxcontrib-serializinghtml==1.1.3\n",
      "sphinxcontrib-websupport==1.1.2\n",
      "spyder==3.3.6\n",
      "spyder-kernels==0.5.1\n",
      "SQLAlchemy==1.3.5\n",
      "statsmodels==0.10.0\n",
      "sympy==1.4\n",
      "tables==3.5.2\n",
      "tblib==1.4.0\n",
      "tensorboard==2.0.2\n",
      "tensorflow==2.0.0\n",
      "tensorflow-estimator==2.0.1\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.2\n",
      "testpath==0.4.2\n",
      "toolz==0.10.0\n",
      "tornado==6.0.3\n",
      "tqdm==4.32.1\n",
      "traitlets==4.3.2\n",
      "trueskill==0.4.5\n",
      "typed-ast==1.3.4\n",
      "typing==3.6.4\n",
      "unicodecsv==0.14.1\n",
      "urllib3==1.24.2\n",
      "wcwidth==0.1.7\n",
      "webencodings==0.5.1\n",
      "Werkzeug==0.15.5\n",
      "widgetsnbextension==3.5.0\n",
      "win-inet-pton==1.1.0\n",
      "win-unicode-console==0.5\n",
      "wincertstore==0.2\n",
      "wrapt==1.11.2\n",
      "xlrd==1.2.0\n",
      "XlsxWriter==1.1.8\n",
      "xlwings==0.15.8\n",
      "xlwt==1.3.0\n",
      "xmltodict==0.12.0\n",
      "zict==1.0.0\n",
      "zipp==0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape X_mat_train:\", X_mat_train.shape)\n",
    "print(\"Shape l_train:\", l_train.shape)\n",
    "print(\"Shape X_mat_test:\", X_mat_test.shape)\n",
    "print(\"Shape l_test:\", l_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data as matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display 10 images of the training dataset to explore the latter.\n",
    "All figures are displayed using `matplotlib.pyplot`. We also use a very convenient module `matplotlib.gridspec` which specifies how subplots of a figure are organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "fig = plt.figure(figsize = (12, 2))\n",
    "gs = gridspec.GridSpec(nrows = 1, ncols = n_examples, left = 0.1, bottom = 0.25, \n",
    "                       right = 0.95, top = 0.95, wspace = 0.0, hspace = 0.0)\n",
    "for i in range(0, n_examples):\n",
    "    ax1 = plt.subplot(gs[i])\n",
    "    plt.imshow(X_mat_train[i,:,:], cmap = \"gray\")\n",
    "    ax1.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting each matrix into a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are not going to take advantage of the 2 dimensional structure of the data.\n",
    "Instead, we will convert all matrices of size $n \\times n$ into vectors of size $d = n^2$.\n",
    "Furtheremore, components of an image are originally comprised between 0 and 255; we want to work with data between 0 and 1 and thus normalize accordingly.\n",
    "\n",
    "We obtain $X_{train} \\in [0,1]^{n_{samples,train} \\times d}$ and $X_{test} \\in [0,1]^{n_{samples,test} \\times d}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = n * n\n",
    "X_train = X_mat_train.reshape(n_samples_train, d) / 255.\n",
    "X_test = X_mat_test.reshape(n_samples_test, d) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape X_train:\", X_train.shape)\n",
    "print(\"Shape l_train:\", l_train.shape)\n",
    "print(\"Shape X_test:\", X_test.shape)\n",
    "print(\"Shape l_test:\", l_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle of representation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample $x \\in \\mathbb{R}^d$ of our dataset will be represented in a new space as $z \\in \\mathbb{R}^h$, with $h < d$, and will then be reconstructed in the original space as $y \\in \\mathbb{R}^d$ with some approximation, which is assessed by the reconstruction error $\\epsilon(x) = \\frac{1}{d} \\sum_{j=1}^d | x_j - y_j |^2$.\n",
    "\n",
    "The whole process can be summed up as:\n",
    "\n",
    "$x \\in \\mathbb{R}^d \\rightarrow z = f(x) \\in \\mathbb{R}^h \\rightarrow y = g(f(x)) \\in \\mathbb{R}^d$\n",
    "\n",
    "or matrix-wise:\n",
    "\n",
    "$X \\in \\mathbb{R}^{n_{samples} \\times d} \\rightarrow Z = f(X) \\in \\mathbb{R}^{n_{samples} \\times h} \\rightarrow Y = g(f(X)) \\in \\mathbb{R}^{n_{samples} \\times d}$\n",
    "\n",
    "Learning the representation in the new embedded space $\\mathbb{R}^{h}$ will be driven by how well we can reconstruct the original data $X$ as $Y$ by _going through_ the embedded space, i.e. the representation will be learnt by minimizing the reconstruction error over the whole dataset:\n",
    "\n",
    "<center>$\\epsilon(X) = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} \\frac{1}{d} \\sum_{j=1}^d | X_{ij} - Y_{ij} |^2$.</center>\n",
    "\n",
    "Specifying how we choose the functions $f$ and $g$ constitutes a model of representation learning. In the following, we will focus on Principal Component Analysis and Autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis is one of the simplest technique to represent data in a space of reduced dimension.\n",
    "Basically, it transforms the data to a new coordinate system such that the greatest variance by some projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.\n",
    "If we choose to keep only the first $h$ dimensions of this new coordinate system, we have a new representation of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing PCA by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this section is to perform PCA \"by hand\" on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color=red> First, don't forget to center the data to obtain $X^0_{train}$.\n",
    "\n",
    "Second, perform an SVD decomposition of this centered matrix as $X^0_{train} = U \\mathrm{Diag}(s) V^T$, with:\n",
    "- $X^0_{train} \\in \\mathbb{R}^{n_{train} \\times d}$,\n",
    "- $U \\in \\mathbb{R}^{n_{train} \\times n_{train}}$,\n",
    "- $Diag(s) \\in \\mathbb{R}^{n_{train} \\times d}$,\n",
    "- $V \\in \\mathbb{R}^{d \\times d}$.\n",
    "\n",
    "An implementation of the SVD decomposition is available via the famous `numpy` library.\n",
    "For numerical efficiency, we set `full_matrices = False` in `np.linalg.svd`, which will reduce their dimensions to:\n",
    "- $U \\in \\mathbb{R}^{n_{train} \\times d}$,\n",
    "- $Diag(s) \\in \\mathbb{R}^{d \\times d}$,\n",
    "- $V \\in \\mathbb{R}^{d \\times d}$.\n",
    "    \n",
    "Third, you can plot the singular values to get a hint on the number of singular values needed to have a proper tradeoff between compression and data fidelity.\n",
    "    \n",
    "You can obtain the representation of our data in a new space of dimension $h$ by truncating the matrix $V$ and computing:\n",
    "\n",
    "$Z^0_{train} = f(X^0_{train}) = X^0_{train} V_h^T \\in \\mathbb{R}^{n \\times h}$,\n",
    "\n",
    "where $V_h \\in \\mathbb{R}^{h\\times d}$. \n",
    "    \n",
    "Reconstruct the approximation $\\tilde{Y}_{train}$ from this representation for several values of $h$ (starting with $h=2$) and do the same with $\\tilde{Y}_{test}$.\n",
    "    \n",
    "Plot the reconstruction error as well as the explained variance ratio when $h$ varies.\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing PCA using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is rather important to understand how a PCA works behind the scenes, which is why we implemented it almost from scratch.\n",
    "A PCA can nevertheless be computed automatically using `scikit-learn` and its `decomposition` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "m_train=X_train.mean(axis = 0)\n",
    "X0_train=X_train - m_train\n",
    "h = 2\n",
    "pca = PCA(n_components = h)\n",
    "pca.fit(X0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notably check what the variance of our data in the new coordinate system along each axis is by printing `pca.explained_variance_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Explained variance for axes 1 and 2:\", pca.explained_variance_)\n",
    "print(\"Ratios of explained variance for axes 1 and 2:\", \n",
    "      pca.explained_variance_ratio_)\n",
    "print(\"Total ratio of explained variance of the data in this new space:\", \n",
    "      np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furtheremore, `pca.transform` plays the role of the projection operator $V_h$ that we have introduced earlier. The application of $V_h^T$ is done through `pca.inverse_transform`\n",
    "We can therefore reconstruct the data and compute the reconstruction error which is, unsurprisingly, the same as the one computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0_train = pca.transform(X0_train)\n",
    "Y0_train = pca.inverse_transform(Z0_train)\n",
    "Y_train = Y0_train + m_train\n",
    "e_pca_train = mean_squared_error(X_train, Y_train)\n",
    "print(\"SKL PCA reconstruction error with h =\", h, \"PCs:\", str(round(e_pca_train, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned, learning a representation of our data in a space of reduced dimension and reconstructing it in the original space can be done for various kinds of data.\n",
    "However, one of the benefits of working with images is that we can visualize the reconstructed data and compare it to the original ones.\n",
    "This is not always possible and it can be much harder to assess how well we have reconstructed data.\n",
    "\n",
    "Let us see the reconstruction of our data in this case. We first need to convert our reconstructed vectors to matrices to display images, we hence define $Y^{mat}_{train} \\in \\mathbb{R}^{n_{samples} \\times n \\times n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mat_train = Y_train.reshape(60000, 28, 28)\n",
    "n_examples = 10\n",
    "fig = plt.figure(figsize = (12, 4))\n",
    "gs = gridspec.GridSpec(nrows = 2, ncols = n_examples, left = 0.1, \n",
    "                       bottom = 0.25, right = 0.95, top = 0.95,\n",
    "                       wspace = 0.0, hspace = 0.0)\n",
    "for i in range(0, n_examples):\n",
    "    ax1 = plt.subplot(gs[i])\n",
    "    plt.imshow(X_mat_train[i,:,:], cmap = \"gray\")\n",
    "    ax1.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax2 = plt.subplot(gs[n_examples+i])\n",
    "    plt.imshow(Y_mat_train[i,:,:], cmap = \"gray\")\n",
    "    ax2.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reconstruction is not particularly good with $h = 2$ only.\n",
    "There is actually nothing very surprising since the dimension of the representation space is very low, probably too low to explain all the information and variability of our data.\n",
    "\n",
    "Let's try with several values of $h$ to see how the results change.\n",
    "We are going to store all our results in dictionaries for convenience and reusability.\n",
    "This is particularly important when working with lots of different models (it will be even more crucial for autoencoders).\n",
    "\n",
    "Obviously, the maximum value for $h$ is $d$, that of the data itself.\n",
    "\n",
    "For each value of $h$, we compute the PCA, the reconstruction error, the total ratio of variance explained, and we also display both the original image and the associated reconstruction image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pca = {}\n",
    "dict_e_pca_train = {}\n",
    "dict_var_exp_train = {}\n",
    "\n",
    "for h in [2, 5, 10, 20, 50, 100, 784]:\n",
    "    dict_pca[h] = PCA(n_components = h)\n",
    "    dict_pca[h].fit(X0_train)\n",
    "    pca = dict_pca[h]\n",
    "    Z0_train = pca.transform(X0_train)\n",
    "    Y0_train = pca.inverse_transform(Z0_train)\n",
    "    Y_train = Y0_train + m_train\n",
    "    e_pca_train = mean_squared_error(X_train, Y_train)\n",
    "    var_exp_train = np.sum(pca.explained_variance_ratio_)\n",
    "    dict_e_pca_train[h] = e_pca_train\n",
    "    dict_var_exp_train[h] = var_exp_train\n",
    "    print(\"SKL PCA, h =\", h, \"PCs, reconstruction error:\", str(round(e_pca_train, 3)),\n",
    "          \"total ratio of variance explained:\", str(round(var_exp_train, 3)))\n",
    "    Y_mat_train = Y_train.reshape(n_samples_train, n, n)\n",
    "    n_examples = 10\n",
    "    fig = plt.figure(figsize = (12, 4))\n",
    "    gs = gridspec.GridSpec(nrows = 2, ncols = n_examples, left = 0.1, bottom = 0.25, \n",
    "                           right = 0.95, top = 0.95, wspace = 0.0, hspace = 0.0)\n",
    "    for i in range(0, n_examples):\n",
    "        ax1 = plt.subplot(gs[i])\n",
    "        plt.imshow(X_mat_train[i,:,:], cmap = \"gray\")\n",
    "        ax1.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "        ax2 = plt.subplot(gs[n_examples+i])\n",
    "        plt.imshow(Y_mat_train[i,:,:], cmap = \"gray\")\n",
    "        ax2.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, we see that results improve with increasing $h$ and that the reconstructed images start to look decent for $h = 20$. For $h = d$, the original image, the representation in the embedded space and the reconstruction are all the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PCA with $h = 2$ allows to obtain a two dimensional representation of our data that we can then plot.\n",
    "It is an interesting, easy and quick way (although slightly naive too!) to see how the data is distributed in this new space, whether clusters might be present or not, etc.\n",
    "Let us apply this technique to the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca.fit(X0_train)\n",
    "Z0_train_pca = pca.transform(X0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have good looking figures, we define a bunch of `matplotlib` options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_digits = 10\n",
    "fs = 20\n",
    "plt.rc('axes', facecolor = \"white\", linewidth = 1, grid = False, edgecolor = \"black\",\n",
    "       titlesize = fs, labelsize = fs)\n",
    "plt.rc('font', size = fs)\n",
    "plt.rc('xtick', labelsize = fs)\n",
    "plt.rc('ytick', labelsize = fs)\n",
    "plt.rc('legend', fontsize = fs)\n",
    "plt.rc('figure', titlesize = fs, figsize = (15, 10))\n",
    "colors = plt.cm.jet(np.linspace(0, 1, n_digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each digit $k$ between 0 and 9, we find the indices in our training dataset which corresponds to $k$, and plot the representation of $n_{points} = 500$ points (so as not to overload the image) corresponding to this digit.\n",
    "\n",
    "All instances of a given digit $k$ are displayed in the same color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_points = 500\n",
    "\n",
    "fig = plt.figure()\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train == digit)\n",
    "    ind = ind[0][0:n_points]\n",
    "    plt.scatter(Z0_train_pca[ind,0], Z0_train_pca[ind,1], \n",
    "                label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "plt.legend(bbox_to_anchor=(1.12, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most instances of a given digit $k$ are grouped together, although there exist (possibly strong) overlaps between different groups of digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another technique worth mentioning to display data in 2 dimensions is t-distributed Stochastic Neighbor Embedding (t-SNE).\n",
    "First, t-SNE constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects have a high probability of being picked while dissimilar points have an extremely small probability of being picked.\n",
    "It defines a similar probability distribution over the points in the low-dimensional map, and it then minimizes the Kullback–Leibler divergence between the two distributions with respect to the locations of the points in the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it can be numerically expensive, we only compute it on a subset of the training set of size `n_samples_tsne = 2000`. We also compute the required time to compute it using the `time` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "r_tsne = TSNE(n_components = 2, perplexity = 50.0, early_exaggeration = 20.0)\n",
    "n_samples_tsne = 2000 ## computing t-SNE over the whole dataset is rather costly\n",
    "ti_tsne = time.time()\n",
    "Z0_train_tsne = r_tsne.fit_transform(X0_train[0:n_samples_tsne,:])\n",
    "t_tsne = time.time() - ti_tsne\n",
    "print(\"Time TSNE with\", n_samples_tsne, \"samples:\", str(round(t_tsne, 2)), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the same kind of figure as for PCA.\n",
    "You can play with the parameters of `perplexity` and `early_exaggeration` to see how it changes the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train[0:n_samples_tsne] == digit)\n",
    "    plt.scatter(Z0_train_tsne[ind,0], Z0_train_tsne[ind,1], label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "    plt.xlabel(\"t-SNE 1\")\n",
    "    plt.ylabel(\"t-SNE 2\")\n",
    "plt.legend(bbox_to_anchor=(1.12, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups of digits appear to be much better separated than for PCA.\n",
    "In this supervised case, where digit labels are available for confirmation, t-SNE appears very relevant.\n",
    "In general, one must remain careful though:\n",
    "while t-SNE plots often seem to display clusters, the visual clusters can be influenced strongly by the chosen parameterization and therefore a good understanding of the parameters for t-SNE is necessary. Such \"clusters\" can be shown to even appear in non-clustered data, and thus may be false findings. Interactive exploration may thus be necessary to choose parameters and validate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us recall that with a PCA we learn a representation as:\n",
    "\n",
    "$Y^0_{train} = g(Z^0_{train}) = Z^0_{train} V_h$,\n",
    "\n",
    "i.e.:\n",
    "\n",
    "$Y^0_{train} = g(f(X^0_{train})) = X^0_{train} V_h^T V_h$.\n",
    "\n",
    "Can we find other functions $f$ and $g$ so that the reconstruction error:\n",
    "\n",
    "<center>$\\epsilon(X) = \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} \\frac{1}{d} \\sum_{j=1}^d | X_{ij} - Y_{ij} |^2$.</center>\n",
    "\n",
    "is even lower? This was indeed our a priori criterion to learn a good representation in the space of dimension $h$.\n",
    "\n",
    "An autoencoder is a type of neural network that is comprised of two parts:\n",
    "- an encoder, that _encodes_ the original data in a space of reduced dimension (this is our representation),\n",
    "- a decoder, that _decodes_ the representation back in the original space.\n",
    "\n",
    "Note that this is precisely what we have done so far with PCA, which is indeed equivalent to a particular architecture of an autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder is nothing more than a neural network with layers of weights and activation functions.\n",
    "If $x$ is an input vector (let us recall that in our case this is a vectorized image), the most simple autoencoder can be written in the following way:\n",
    "- encoder: $x \\rightarrow z = f(x) = \\sigma_1(W_1 x)$,\n",
    "- decoder: $z \\rightarrow y = g(z) = \\sigma_2(W_2 x)$.\n",
    "\n",
    "where $W_1$ and $\\sigma_1$ (resp. $W_2$ and $\\sigma_2$) are the weight matrix and the activation function of the first [encoder] layer (resp. the second [decoder] layer). The output of the autoencoder is then simply: $y = g(f(x)) = \\sigma_2(W_2 \\sigma_1 (W_1 x))$.\n",
    "\n",
    "If we choose $W_1 = W_2^T = V_h^{PCA}$ and $\\sigma_1 = \\sigma_2 = Id$, we are left with nothing but the PCA model.\n",
    "However, there may be better choices of $W_1$, $W_2$, $\\sigma_1$ and $\\sigma_2$ to minimize the reconstruction error $\\epsilon$.\n",
    "\n",
    "The strength of neural networks is that they are nonlinear thanks to the (usually nonlinear) activation functions.\n",
    "In our case, once activation functions $\\sigma_1$ and $\\sigma_2$ are chosen, we can optimize the weights of the autoencoder so as to minimize the reconstruction error, i.e. we solve:\n",
    "\n",
    "<center>$W_1, W_2 = \\arg \\min \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} \\frac{1}{d} \\sum_{j=1}^d | X_{ij} - Y_{ij} |^2$.</center>\n",
    "\n",
    "where $Y = \\sigma_2(W_2 \\sigma_1 (W_1 X))$. This is done using backpropagation.\n",
    "\n",
    "We make a first attempt replacing the identity activation function by sigmoids and draw the reconstruction error for the train and test sets.\n",
    "\n",
    "The last layer gives us the reconstructed data in the original space. Notice that we use a `sigmoid` function in order to have output data between 0 and 1, as for the input data (recall that we have scaled it in the very beginning of this notebook).\n",
    "\n",
    "We use `keras` to build these autoencoders.\n",
    "We first define a `Sequential()` `model` and `add` to it different (`Dense`) layers.\n",
    "\n",
    "The last step of defining a `keras` model is to compile it by specifying the objective function, i.e. the loss, which is here the `mean_squared_error` between the input and the output of the model, i.e. precisely:\n",
    "\n",
    "<center>$\\arg \\min \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} \\frac{1}{d} \\sum_{j=1}^d | X_{ij} - Y_{ij} |^2$.</center>\n",
    "\n",
    "We also need to specify which optimizer we choose, `Adam()` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, activation = \"sigmoid\", input_shape = (784,)))\n",
    "model.add(Dense(784, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"mean_squared_error\", optimizer = Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a summary of the model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit the model and save the results in an `history` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "history = model.fit(X_train, X_train, batch_size = 128, epochs = n_epochs, verbose = 1,\n",
    "                    validation_data = (X_test, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the reconstruction loss during training for both the train and test sets, and compare them to that of PCA, for the same number of components (here 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], c = 'blue', label = \"simple AE\" + \" train\")\n",
    "plt.plot(history.history['val_loss'], c = 'blue', label = \"simple AE\" + \" test\", linestyle = \"--\")\n",
    "plt.axhline(dict_e_pca_train[2], c = 'blue', label = \"PCA reconstruction error with 2 components\")\n",
    "plt.xlim(0, n_epochs-1)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(bbox_to_anchor = (1.02, 1.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such a simple architecture, we see that the autoencoder is less efficient than the simpler PCA.\n",
    "We therefore explore more complex architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build autoencoders with more complicated architectures than the simple one we just described.\n",
    "For instance, we might want to increase the depth of our network by adding other layers to both the encoder and decoder parts and the dimension of each layer need not be the same. It will comprise more layers, hence more weight matrices, but the principle remains the same:\n",
    "\n",
    "<center>$\\{W_l\\}_{1 \\leq l \\leq L} = \\arg \\min \\frac{1}{n_{samples}} \\sum_{i=1}^{n_{samples}} \\frac{1}{d} \\sum_{j=1}^d | X_{ij} - Y_{ij} |^2$,</center>\n",
    "\n",
    "where $L$ is the number of layers of the model and $Y = \\sigma_L(W_L \\dots \\sigma_1(W_1 X))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "Build an autoencoder with the following architecture:\n",
    "- a layer with 512 units and activation function `elu`, followed by\n",
    "- a layer with 128 units and activation function `elu`, followed by\n",
    "- a layer with 2 units and a `linear` activation function, followed by\n",
    "- a layer with 128 units and activation function `elu`, followed by\n",
    "- a layer with 512 units and activation function `elu`, followed by\n",
    "- a layer with 784 units and activation function `sigmoid`.\n",
    "\n",
    "Train the model and visualize the reconstruction loss, compare it with the PCA reconstruction.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explor a large variety of different architectures of autoencoders, we need an efficient and concise way of defining them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building autoencoders in a generic and efficient way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to study different kinds of architectures in an efficient way, we are going to store once again all our results inside dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_model = {}\n",
    "dict_history = {}\n",
    "dict_encoder = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us write a function `build_autoencoder` which takes as an input the string representing the architecture of our autoencoder. These strings will be the keys of the dictionaries. For instance `\"512,elu-128,elu-2,Rlinear-128,elu-512,elu-784,sigmoid\"` will build the architecture we just described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a specific trick for our problem: in the string, we add an 'R' to the name of the activation function before the representation layer. It will help us later retrieve the encoded data representation. For the autoencoder construction in Keras, we will we drop this `R` from the name of the activation function when the activation function of a layer starts with `R`, and name the layer `representation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_arch(arch):\n",
    "    layers = arch.split(\"-\")\n",
    "    return [layer.split(\",\") for layer in layers]\n",
    "\n",
    "def build_autoencoder(arch, d):\n",
    "    arch_split = split_arch(arch)\n",
    "    layer0 = arch_split[0]\n",
    "    model = Sequential()\n",
    "    if layer0[1].startswith(\"R\"):\n",
    "        model.add(Dense(int(layer0[0]), activation = layer0[1][1:], \n",
    "                        name = \"representation\", input_shape = (d,)))\n",
    "    else:\n",
    "        model.add(Dense(int(layer0[0]), activation = layer0[1], input_shape = (d,)))\n",
    "    for i in range(1, len(arch_split)):\n",
    "        layer = arch_split[i]\n",
    "        if layer[1].startswith(\"R\"):\n",
    "            model.add(Dense(int(layer[0]), activation = layer[1][1:], \n",
    "                            name = \"representation\"))\n",
    "        else:\n",
    "            model.add(Dense(int(layer[0]), activation = layer[1]))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different values of $h$, we define both a naive architecture of an autoencoder (with only 3 layers in total) and a more refined architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "archs = []\n",
    "hs = [2] ## We could try different values of h: 2, 5, ....\n",
    "for h in hs:\n",
    "    archs.append(str(h) + \",Rlinear-784,sigmoid\")\n",
    "    archs.append(\"512,elu-128,elu-\" + str(h) + \",Rlinear-128,elu-512,elu-784,sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train all these autoencoders for 20 epochs and store their training history.\n",
    "\n",
    "It actually takes some time to obtain all results, you can increase the number of dimensions for the representation space, say `hs = [2, 5, 10, 20, 50, 100, 784]`, and increase the number of epochs to 100 if you want to see the complete training, but you may want to go for lunch while it runs to wait for the results.\n",
    "\n",
    "Note that for refined autoencoders, there are many more weight parameters to learn, the training time is therefore much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "## the full training can take ~15 minutes\n",
    "\n",
    "ti_training = time.time()\n",
    "for arch in archs:\n",
    "    print(arch)\n",
    "    dict_model[arch] = build_autoencoder(arch, d)\n",
    "    dict_history[arch] = dict_model[arch].fit(X_train, X_train, batch_size = 128, \n",
    "                                              epochs = n_epochs, verbose = 1, \n",
    "                                              validation_data = (X_test, X_test))\n",
    "t_training = time.time() - ti_training\n",
    "print(\"Time for training autoencoders:\", t_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each size of the representation, we plot the training curves of both the simple autoencoders and the refined one. We also add to the plot the value of the PCA reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "i = 0\n",
    "for h in hs:\n",
    "    ci = colors[np.mod(4*i, len(colors))]\n",
    "    arch = str(h) + \",Rlinear-784,sigmoid\"\n",
    "    history = dict_history[arch]\n",
    "    plt.plot(history.history['loss'], c = ci, label = str(h) + \" train\")\n",
    "    plt.plot(history.history['val_loss'], c = ci, label = str(h) + \" test\", linestyle = \"--\")\n",
    "    plt.axhline(dict_e_pca_train[h], c = ci)\n",
    "    arch = \"512,elu-128,elu-\" + str(h) + \",Rlinear-128,elu-512,elu-784,sigmoid\"\n",
    "    history = dict_history[arch]\n",
    "    plt.plot(history.history['loss'], c = ci, marker = \"*\", label = str(h) + \" R train\")\n",
    "    plt.plot(history.history['val_loss'], c = ci,  label = str(h) + \" R test\", marker = \"s\")\n",
    "    i += 1\n",
    "plt.xlim(0, n_epochs-1)\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(bbox_to_anchor = (1.02, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two main things can be noted:\n",
    "- the autoencoders (even simple ones) almost always outperform the PCA for a sufficiently large number of epochs,\n",
    "- the refined autoencoders are much more efficient than the simple ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the 2D representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display the representation in 2D in the following case:\n",
    "  - the PCA,\n",
    "  - t-SNE,\n",
    "  - the simple autoencoder,\n",
    "  - the refined autoencoder,\n",
    "  \n",
    "in order to see how the data (and groups of digits) spread in the 2 dimensional representation space in each case.\n",
    "\n",
    "To obtain the representation of an autoencoder, we define a new `Model()` which takes the same input as the autoencoder, and use `get_layer().output` to obtain the output of the layer named `representation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_plot = 100\n",
    "\n",
    "plt.figure(figsize = (15, 15))\n",
    "gs = gridspec.GridSpec(nrows = 2, ncols = 2, left = 0.1, bottom = 0.25, right = 0.95, top = 0.95,\n",
    "                       wspace = 0.2, hspace = 0.2)\n",
    "\n",
    "## PCA\n",
    "ax1 = plt.subplot(gs[0])\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train == digit)\n",
    "    ind = ind[0][0:n_samples_plot]\n",
    "    pca = dict_pca[2]\n",
    "    Z0_train_pca = pca.transform(X0_train)\n",
    "    plt.scatter(Z0_train_pca[ind,0], Z0_train_pca[ind,1], label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "ax1.title.set_text(\"PCA\")\n",
    "\n",
    "## t-SNE\n",
    "ax2 = plt.subplot(gs[1])\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train == digit)\n",
    "    ind = ind[0][0:n_samples_plot]\n",
    "    plt.scatter(Z0_train_tsne[ind,0], Z0_train_tsne[ind,1], label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "ax2.title.set_text(\"t-SNE\")\n",
    "\n",
    "## Simple AE\n",
    "arch = \"2,Rlinear-784,sigmoid\"\n",
    "dict_encoder[arch] = Model(dict_model[arch].input, dict_model[arch].get_layer(\"representation\").output)\n",
    "Z_train_ = dict_encoder[arch].predict(X_train)\n",
    "ax3 = plt.subplot(gs[2])\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train == digit)\n",
    "    ind = ind[0][0:n_samples_plot]\n",
    "    plt.scatter(Z_train_[ind,0], Z_train_[ind,1], label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "ax3.title.set_text(\"Simple AE\")\n",
    "\n",
    "## Refined AE\n",
    "arch = \"512,elu-128,elu-2,Rlinear-128,elu-512,elu-784,sigmoid\"\n",
    "dict_encoder[arch] = Model(dict_model[arch].input, dict_model[arch].get_layer(\"representation\").output)\n",
    "Z_train_ = dict_encoder[arch].predict(X_train)\n",
    "ax4 = plt.subplot(gs[3])\n",
    "for digit in range(0, 10):\n",
    "    ind = np.where(l_train == digit)\n",
    "    ind = ind[0][0:n_samples_plot]\n",
    "    plt.scatter(Z_train_[ind,0], Z_train_[ind,1], label = str(digit), color =  colors[digit], alpha = 0.7, s = 150)\n",
    "ax4.title.set_text(\"Refined AE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can visualize the reconstruction of our images to assess how well they are reconstructed.\n",
    "For each $h$, we display:\n",
    "- the original image,\n",
    "- the PCA reconstruction,\n",
    "- the simple autoencoder reconstruction,\n",
    "- the refined autoencoder reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 10\n",
    "\n",
    "for h in hs:\n",
    "    ## PCA\n",
    "    pca = dict_pca[h]\n",
    "    Z0_train = pca.transform(X0_train[:n_examples])\n",
    "    Y0_train_pca_ex = pca.inverse_transform(Z0_train)\n",
    "    Y_train_pca_ex = Y0_train_pca_ex + m_train\n",
    "    Y_mat_train_pca_ex = Y_train_pca_ex.reshape(n_examples, n, n)\n",
    "    ## Basic AE\n",
    "    arch = str(h) + \",Rlinear-784,sigmoid\"\n",
    "    Y_train_bae_ex = dict_model[arch].predict(X_train[0:n_examples,:])\n",
    "    Y_mat_train_bae_ex = Y_train_bae_ex.reshape(n_examples, n, n)\n",
    "    ## Refined AE\n",
    "    arch = \"512,elu-128,elu-\" + str(h) + \",Rlinear-128,elu-512,elu-784,sigmoid\"\n",
    "    Y_train_rae_ex = dict_model[arch].predict(X_train[0:n_examples,:])\n",
    "    Y_mat_train_rae_ex = Y_train_rae_ex.reshape(n_examples, n, n)\n",
    "\n",
    "    fig = plt.figure(figsize = (12, 8))\n",
    "    gs = gridspec.GridSpec(nrows = 4, ncols = n_examples, left = 0.1, bottom = 0.25, right = 0.95, top = 0.95,\n",
    "                           wspace = 0.0, hspace = 0.0)\n",
    "    for i in range(0, n_examples):\n",
    "        ## Real\n",
    "        ax1 = plt.subplot(gs[i])\n",
    "        plt.imshow(X_mat_train[i,:,:], cmap = \"gray\")\n",
    "        ax1.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax1.get_xaxis().set_visible(False)\n",
    "        ax1.get_yaxis().set_visible(False)\n",
    "        fig.text(0.07, 0.87, \"Real\", va = \"center\", rotation = \"vertical\")\n",
    "        ## PCA\n",
    "        ax2 = plt.subplot(gs[n_examples+i])\n",
    "        plt.imshow(Y_mat_train_pca_ex[i,:,:], cmap = \"gray\")\n",
    "        ax2.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax2.get_xaxis().set_visible(False)\n",
    "        ax2.get_yaxis().set_visible(False)\n",
    "        fig.text(0.07, 0.69, \"PCA\", va = \"center\", rotation = \"vertical\")\n",
    "        ## Basic AE\n",
    "        ax3 = plt.subplot(gs[2*n_examples+i])\n",
    "        plt.imshow(Y_mat_train_bae_ex[i,:,:], cmap = \"gray\")\n",
    "        ax3.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        ax3.get_yaxis().set_visible(False)\n",
    "        fig.text(0.07, 0.51, \"Basic AE\", va = \"center\", rotation = \"vertical\")\n",
    "        ## Refined AE\n",
    "        ax4 = plt.subplot(gs[3*n_examples+i])\n",
    "        plt.imshow(Y_mat_train_rae_ex[i,:,:], cmap = \"gray\")\n",
    "        ax4.set(adjustable = \"datalim\", aspect = \"auto\")\n",
    "        ax4.get_xaxis().set_visible(False)\n",
    "        ax4.get_yaxis().set_visible(False)\n",
    "        fig.text(0.07, 0.33, \"Ref. AE\", va = \"center\", rotation = \"vertical\")\n",
    "    plt.suptitle(\"h = \" + str(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again notice that:\n",
    "- reconstructed images are much better with the refined autoencoders than PCA,\n",
    "- reconstructed images of the refined autoencoders are much better than those of the simple one, whence the importance of designing a good architecture of our autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to tackle the problem of clustering our representations to try to identify meaningful groups.\n",
    "Usually we do not know how many clusters there are; here we are going to assume that we have $K = 10$ clusters.\n",
    "\n",
    "We are going to use $K$-means to do so and initialize our centroids with the `kmeans++` method.\n",
    "Note that we could also initialize randomly our centroids which might yield slightly better results in terms of clustering indices. You can try to set `n_random = 10` to launch $K$-means with such an initialization and see the results it yields.\n",
    "\n",
    "For each architecture of our autoencoders, we are going to cluster the representation of our data and store the results in a dictionary `dict_kmeans`. We will also compute two internal clustering indices: the silhouette score and the Davies-Bouldin score. They will be stored in a `DataFrame` (using the `pandas` module) `df` that will sum up the clustering results for each architecture. Note that two different values of a score can be compared only if they are computed on the same data, i.e. the same representation. `DataFrames` are very practical for this task since you can then filter your results based on a condition (a given architecture, a given dimension of the representation, etc.) or find the maximum value of a given variable (e.g. the Davies-Bouldin index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import pandas as pd\n",
    "\n",
    "columns = [\"arch\", \"h\", \"k\", \"init\", \"silhouette\", \"davies_bouldin\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "dict_kmeans = {}\n",
    "n_random = 1              # number of different random initializations\n",
    "n_samples_kmeans = 1000    # set to 60000 if you want to take into account all data (longer training)\n",
    "range_k = range(10, 11)     # we study results for k = 10 only, feel free to investigate further, range(5, 15) for instance\n",
    "\n",
    "## the training of each architecture usually takes between 1 and 2 minutes with all data and n_random = 0\n",
    "\n",
    "for h in hs:\n",
    "    print(\"h:\", h)\n",
    "    for arch in [str(h) + \",Rlinear-784,sigmoid\",\n",
    "                 \"512,elu-128,elu-\" + str(h) + \",Rlinear-128,elu-512,elu-784,sigmoid\"]:\n",
    "        print(\"  arch:\", arch)\n",
    "        ti_clustering = time.time()\n",
    "        dict_encoder[arch] = Model(dict_model[arch].input,\n",
    "                                   dict_model[arch].get_layer(\"representation\").output)\n",
    "        Z_train = dict_encoder[arch].predict(X_train)\n",
    "        Z_train = Z_train[0:n_samples_kmeans,:]\n",
    "        dict_kmeans[arch] = {}\n",
    "        for k in range_k:\n",
    "            dict_kmeans[arch][k] = KMeans(n_clusters = k).fit(Z_train)\n",
    "            sil = silhouette_score(Z_train, dict_kmeans[arch][k].labels_)\n",
    "            db = davies_bouldin_score(Z_train, dict_kmeans[arch][k].labels_)\n",
    "            df = df.append({\"arch\": arch, \"h\": h, \"k\": k, \n",
    "                            \"init\": \"kmeans++\", \"silhouette\": sil, \n",
    "                            \"davies_bouldin\": db},\n",
    "                           ignore_index = True)\n",
    "            for l in range(0, n_random):\n",
    "                km = KMeans(n_clusters = k, init = \"random\").fit(Z_train)\n",
    "                sil = silhouette_score(Z_train, km.labels_)\n",
    "                db = davies_bouldin_score(Z_train, km.labels_)\n",
    "                df = df.append({\"arch\": arch, \"h\": h, \"k\": k, \n",
    "                                \"init\": \"random\", \"silhouette\": sil, \n",
    "                                \"davies_bouldin\": db},\n",
    "                               ignore_index = True)\n",
    "        t_clustering = time.time() - ti_clustering\n",
    "        print(\"Clustering time:\", t_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering results stored in `df` are now available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could define functions to retrieve only the lines that correspond, for instance, to a particular architecture and a number of clusters. We could also find the case for which the silhouette (resp. Davies-Bouldin) index is maximal (resp. minimal). This is useful if we have several clustering algorithms for the same case (i.e. initializing $K$-means with different initializations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(df, arch, k): return df[(df[\"arch\"] == arch) & (df[\"k\"] == k)]\n",
    "def silhouette_max(df): return df.loc[df[\"silhouette\"].idxmax()].silhouette\n",
    "def davies_bouldin_min(df): return df.loc[df[\"davies_bouldin\"].idxmin()].davies_bouldin\n",
    "\n",
    "## If we wish to find the best configuration among a subset of those\n",
    "#arch = \"2,Rlinear-784,sigmoid\"\n",
    "#k = 10\n",
    "#df_filtered = select(df, arch, k)\n",
    "# Here we find the best configurations among all\n",
    "df_filtered=df\n",
    "sil_max = silhouette_max(df_filtered)\n",
    "db_min = davies_bouldin_min(df_filtered)\n",
    "\n",
    "print(df_filtered)\n",
    "print(\"\\n\")\n",
    "print(\"Maximum silhouette score for {} : {:.3f}\".format(arch, sil_max))\n",
    "print(\"Minimum Davies-Bouldin score for {} : {:.3f}\".format(arch, db_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> \n",
    "    For the best configuration obtained. give the confusion matrix for the clusters obtained and the real digit. You will first need to affect each cluster to the digit the most represented in it.\n",
    "    </font>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
